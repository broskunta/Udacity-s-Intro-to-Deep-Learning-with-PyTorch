{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/broskunta/Udacity-s-Intro-to-Deep-Learning-with-PyTorch/blob/main/Part_7_Loading_Image_Data_(Exercises).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFmyjfO_5VEg"
      },
      "source": [
        "# Loading Image Data\n",
        "\n",
        "So far we've been working with fairly artificial datasets that you wouldn't typically be using in real projects. Instead, you'll likely be dealing with full-sized images like you'd get from smart phone cameras. In this notebook, we'll look at how to load images and use them to train neural networks.\n",
        "\n",
        "We'll be using a [dataset of cat and dog photos](https://www.kaggle.com/c/dogs-vs-cats) available from Kaggle. Here are a couple example images:\n",
        "\n",
        "<img src='assets/dog_cat.png'>\n",
        "\n",
        "We'll use this dataset to train a neural network that can differentiate between cats and dogs. These days it doesn't seem like a big accomplishment, but five years ago it was a serious challenge for computer vision systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6xQUIGXO5VEk"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import helper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO9L04cn5VEm"
      },
      "source": [
        "The easiest way to load image data is with `datasets.ImageFolder` from `torchvision` ([documentation](http://pytorch.org/docs/master/torchvision/datasets.html#imagefolder)). In general you'll use `ImageFolder` like so:\n",
        "\n",
        "```python\n",
        "dataset = datasets.ImageFolder('path/to/data', transform=transform)\n",
        "```\n",
        "\n",
        "where `'path/to/data'` is the file path to the data directory and `transform` is a list of processing steps built with the [`transforms`](http://pytorch.org/docs/master/torchvision/transforms.html) module from `torchvision`. ImageFolder expects the files and directories to be constructed like so:\n",
        "```\n",
        "root/dog/xxx.png\n",
        "root/dog/xxy.png\n",
        "root/dog/xxz.png\n",
        "\n",
        "root/cat/123.png\n",
        "root/cat/nsdf3.png\n",
        "root/cat/asd932_.png\n",
        "```\n",
        "\n",
        "where each class has its own directory (`cat` and `dog`) for the images. The images are then labeled with the class taken from the directory name. So here, the image `123.png` would be loaded with the class label `cat`. You can download the dataset already structured like this [from here](https://s3.amazonaws.com/content.udacity-data.com/nd089/Cat_Dog_data.zip). I've also split it into a training set and test set.\n",
        "\n",
        "### Transforms\n",
        "\n",
        "When you load in the data with `ImageFolder`, you'll need to define some transforms. For example, the images are different sizes but we'll need them to all be the same size for training. You can either resize them with `transforms.Resize()` or crop with `transforms.CenterCrop()`, `transforms.RandomResizedCrop()`, etc. We'll also need to convert the images to PyTorch tensors with `transforms.ToTensor()`. Typically you'll combine these transforms into a pipeline with `transforms.Compose()`, which accepts a list of transforms and runs them in sequence. It looks something like this to scale, then crop, then convert to a tensor:\n",
        "\n",
        "```python\n",
        "transform = transforms.Compose([transforms.Resize(255),\n",
        "                                 transforms.CenterCrop(224),\n",
        "                                 transforms.ToTensor()])\n",
        "\n",
        "```\n",
        "\n",
        "There are plenty of transforms available, I'll cover more in a bit and you can read through the [documentation](http://pytorch.org/docs/master/torchvision/transforms.html).\n",
        "\n",
        "### Data Loaders\n",
        "\n",
        "With the `ImageFolder` loaded, you have to pass it to a [`DataLoader`](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader). The `DataLoader` takes a dataset (such as you would get from `ImageFolder`) and returns batches of images and the corresponding labels. You can set various parameters like the batch size and if the data is shuffled after each epoch.\n",
        "\n",
        "```python\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "```\n",
        "\n",
        "Here `dataloader` is a [generator](https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/). To get data out of it, you need to loop through it or convert it to an iterator and call `next()`.\n",
        "\n",
        "```python\n",
        "# Looping through it, get a batch on each loop\n",
        "for images, labels in dataloader:\n",
        "    pass\n",
        "\n",
        "# Get one batch\n",
        "images, labels = next(iter(dataloader))\n",
        "```\n",
        "\n",
        ">**Exercise:** Load images from the `Cat_Dog_data/train` folder, define a few transforms, then build the dataloader."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XYL7-pWSkP3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAyV8uo17n-d",
        "outputId": "39ce5f67-8f67-4d4b-a8cf-d02c03cbebbd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TUudp1_45VEo"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/Othercomputers/My Laptop/Cat_Dog_data/train'\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize(255),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor()])# TODO: compose transforms here\n",
        "\n",
        "dataset = datasets.ImageFolder(data_dir, transform= transform)# TODO: create the ImageFolder\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset = dataset, batch_size= 32, shuffle=True)\n",
        "#torch.utils.data.DataLoader(dataset = dataset, batch_size= = 32, shuffle= True)# TODO: use the ImageFolder dataset to create the DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lj2r1NO_7jDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MFYKO5kn5VEo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "3c77bb4f-213f-46d1-8d9f-83343d655c29"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d9e81831faed>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run this to test your data loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'helper' has no attribute 'imshow'"
          ]
        }
      ],
      "source": [
        "# Run this to test your data loader\n",
        "images, labels = next(iter(dataloader))\n",
        "helper.imshow(images[0], normalize=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBDUAHA_5VEp"
      },
      "source": [
        "If you loaded the data correctly, you should see something like this (your image will be different):\n",
        "\n",
        "<img src='assets/cat_cropped.png' width=244>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFgBMxG75VEp"
      },
      "source": [
        "## Data Augmentation\n",
        "\n",
        "A common strategy for training neural networks is to introduce randomness in the input data itself. For example, you can randomly rotate, mirror, scale, and/or crop your images during training. This will help your network generalize as it's seeing the same images but in different locations, with different sizes, in different orientations, etc.\n",
        "\n",
        "To randomly rotate, scale and crop, then flip your images you would define your transforms like this:\n",
        "\n",
        "```python\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                                                            [0.5, 0.5, 0.5])])\n",
        "```\n",
        "\n",
        "You'll also typically want to normalize images with `transforms.Normalize`. You pass in a list of means and list of standard deviations, then the color channels are normalized like so\n",
        "\n",
        "```input[channel] = (input[channel] - mean[channel]) / std[channel]```\n",
        "\n",
        "Subtracting `mean` centers the data around zero and dividing by `std` squishes the values to be between -1 and 1. Normalizing helps keep the network work weights near zero which in turn makes backpropagation more stable. Without normalization, networks will tend to fail to learn.\n",
        "\n",
        "You can find a list of all [the available transforms here](http://pytorch.org/docs/0.3.0/torchvision/transforms.html). When you're testing however, you'll want to use images that aren't altered (except you'll need to normalize the same way). So, for validation/test images, you'll typically just resize and crop.\n",
        "\n",
        ">**Exercise:** Define transforms for training data and testing data below. Leave off normalization for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8fhmHf1w5VEq"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/Othercomputers/My Laptop/Cat_Dog_data'\n",
        "\n",
        "# TODO: Define transforms for the training data and testing data\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor()])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor()])\n",
        "\n",
        "\n",
        "# Pass transforms in here, then run the next cell to see how the transforms look\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=32)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BSOTuwzt5VEr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "eaf5ad79-5325-4c91-f204-d88701b51470"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7972353308af>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'helper' has no attribute 'imshow'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABpQAAALKCAYAAAA8krI5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAB7CAAAewgFu0HU+AABVOUlEQVR4nO3df5hWdZ038M/A8HNABlBTA3/kOIJlTwRDErIslW7lommttj0kmilldamx/WI3dSti0fUqt8fdNAmzusR9ylBC6zFCkx+GIFuWmFpqQ1FKoQPDz4Hz/OE1tyAz35n75tzz8/W6rrmuY+c73++Z47nP2933fe67IsuyLAAAAAAAAKAVfTr7AAAAAAAAAOjaFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJBU1kLp+eefjx/+8Idx9dVXx7ve9a44/PDDo6KiIioqKuKiiy4qy5p33HFHnHnmmXHUUUfFwIED47jjjosZM2bE6tWry7IeAOUnTwDIi0wBIA/yBIDeqCLLsqxsk1dUtLpv5syZcdttt+W21o4dO+J973tf3HvvvS3u79OnT1x99dVxzTXX5LYmAB1DngCQF5kCQB7kCQC9UYd95N2xxx4bZ555Ztnm/9CHPlQI1mnTpsXixYtjzZo1sWDBgjjxxBNj3759ce2118Ytt9xStmMAoPzkCQB5kSkA5EGeANBblPUJpWuuuSbq6uqirq4uXvOa18Szzz4bJ5xwQkTk+26Nn/70p/H2t789IiKmT58eP/jBD6Jv376F/Zs3b47x48fH73//+6iuro7f/e53MXz48FzWBqD85AkAeZEpAORBngDQG5X1CaV//dd/jb//+7+P17zmNeVcJv793/89IiIqKyvjP//zPw8I1oiIww8/PObPnx8RES+++GLceuutZT0eAPIlTwDIi0wBIA/yBIDeqMM+8q5ctm7dGsuWLYuIiHe84x0xatSoFsedd955cdhhh0VExA9+8IMOOz4Augd5AkBeZAoAeZAnAHQ13b5QeuSRR2L37t0RETF16tRWx/Xv3z9OO+20wu/s2bOnQ44PgO5BngCQF5kCQB7kCQBdTbcvlB5//PHC9pgxY5Jjm/c3NTXFU089VdbjAqB7kScA5EWmAJAHeQJAV1PZ2QdwqDZu3FjYbu3R32ajR48ubNfX18cpp5xS0jot2blzZzzxxBPxmte8Jo444oiorOz2pxagwzQ1NcULL7wQERGnnnpqDBw4sMOPQZ4AdH9dIU8iZApAdydPDiRPAErXVTIlL90+AbZu3VrYHjJkSHJsVVVVYXvbtm1FrbN/MANQPmvWrIm6uroOX1eeAPQsnZUnETIFoCeRJwDkpTMzJS/d/iPvdu7cWdju379/cuyAAQMK2zt27CjbMQHQ/cgTAPIiUwDIgzwBoKvp9k8o7f+IWPMXFbZm165dhe1BgwYVtU59fX2b+9/61rdGxMtN49FHH13U/AC92aZNm2LixIkREXHEEUd0yjHIE4DuryvkSYRMAeju5MnB++UJQGm6SqbkpdsXSkOHDi1st/VIb2NjY2G7rUeFX62tz6rd39FHH13UeABe0Vmfxy1PAHqWzvx+B5kC0HPIkwPJE4DS9YTvoOv2H3m3f4i19SWC+7/jwufDArA/eQJAXmQKAHmQJwB0Nd2+UDrllFMK20888URybPP+ysrKOOmkk8p6XAB0L/IEgLzIFADyIE8A6Gq6faFUV1dX+GLCBx98sNVxu3fvjocffrjwO/369euQ4wOge5AnAORFpgCQB3kCQFfT7QuloUOHxtvf/vaIiPjJT37S6iPAd911VzQ0NERExLnnntthxwdA9yBPAMiLTAEgD/IEgK6myxdKt912W1RUVERFRUVce+21LY75p3/6p4iIaGpqio997GOxd+/eA/Zv3rw5PvOZz0RERHV1dXz4wx8u6zED0PXIEwDyIlMAyIM8AaC7qSzn5CtWrIinn3668M+bN28ubD/99NNx2223HTD+oosuKmmdt73tbfH+978/Fi1aFPfcc0+cccYZceWVV8YxxxwTjz32WMydOzd+//vfR0TE/PnzY/jw4SWtA0DnkCcA5EWmAJAHeQJAb1TWQunWW2+Nb33rWy3uW7lyZaxcufKA/63UcI2I+OY3vxkNDQ1x7733xvLly2P58uUH7O/Tp098/vOfj8suu6zkNQDoHPIEgLzIFADyIE8A6I26/EfetdegQYNi6dKl8d3vfjfOOOOMOPLII6N///4xevTo+MAHPhArVqxo9fFhAGgmTwDIi0wBIA/yBICuoiLLsqyzD6In2LhxY4wePToiIurr62PUqFGdfEQA3Yd76CucC4DSuYceyPkAKI3754GcD4DS9bR7aI95QgkAAAAAAIDyUCgBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACApA4rlJ577rmYPXt2jBkzJqqqqmLEiBFRV1cX119/fWzfvj2XNZ599tn4zGc+E+PHj4/q6uro169fjBgxIt761rfGF77whXj++edzWQeAziNPAMiLTAEgD/IEgN6iIsuyrNyLLFmyJGbMmBENDQ0t7q+trY2lS5dGTU1NyWt8+9vfjlmzZsWOHTtaHTNixIhYtGhRnHHGGSWv05qNGzfG6NGjIyKivr4+Ro0alfsaAD1Ve++h8gSAlGLuoTIFgNbIkwPJE4DS9bR7aNmfUFq/fn1ccMEF0dDQEEOGDIm5c+fGqlWrYtmyZXHppZdGRMSTTz4ZZ511VmzdurWkNVauXBkXXXRR7NixI/r06RMXX3xxLF68ONasWRPf+973Yvr06RER8de//jXOOeec+N3vfpfb3wdAx5AnAORFpgCQB3kCQK+TldmUKVOyiMgqKyuzVatWHbT/uuuuyyIii4jsmmuuKWmNs846qzDHTTfd1OKYT37yk4UxH/vYx0paJ6W+vr4wf319fe7zA/Rk7bmHyhMA2tLee6hMASBFnhxIngCUrqfdQ8v6kXdr1qyJt7zlLRERMWvWrPj6179+0Jh9+/bFG97whtiwYUNUV1fH888/H/369StqnREjRsSWLVti5MiRsXnz5hbHvPTSS1FdXR0REW9+85tj3bp1xf0xbehpj64BdKS27qHyBID2aM89VKYA0BZ5ciB5AlC6nnYPLetH3i1evLiwffHFF7d8AH36xIUXXhgRES+++GIsX7686HV2794dEREnnHBCq2OGDRsWhx9++AHjAege5AkAeZEpAORBngDQG5W1UFqxYkVERFRVVcX48eNbHTd16tTC9sqVK4te5+STT46IiGeeeabVMQ0NDYV3cjSPB6B7kCcA5EWmAJAHeQJAb1TWQmnDhg0REVFTUxOVlZWtjhszZsxBv1OMj3zkIxER8Ze//KXFR4wjIr74xS8eNB6A7kGeAJAXmQJAHuQJAL1R64l3iHbu3Fl4d0Rbnws4fPjwqKqqisbGxqivry96rQ996EOxYsWKuP322+NjH/tYrFu3Ls4+++w4+uij4/e//318+9vfLjyK/M///M/xjne8o+g1Nm7cmNy/adOmoucEoG3yBIC8yBQA8iBPAOitylYobd26tbA9ZMiQNsc3h+u2bduKXqtv377xrW99K6ZPnx5f/vKX49Zbb41bb731gDHTpk2LOXPmlBSsEVH44iwAOpY8ASAvMgWAPMgTAHqrsn3k3c6dOwvb/fv3b3P8gAEDIiJix44dJa23YcOGuP322+Oxxx5rcf/q1atjwYIF8Yc//KGk+QHoHPIEgLzIFADyIE8A6K3KVigNHDiwsL179+42x+/atSsiIgYNGlT0Wg899FBMmjQplixZEq997Wvj29/+dvzpT3+K3bt3R319fdx0000xePDgWLRoUUycODF+/etfF71GfX198mfNmjVFzwlA2+QJAHmRKQDkQZ4A0FuV7SPvhg4dWthuzyO9jY2NEdG+R4X3t2vXrvjHf/zHeOmll+Koo46Khx9+OI466qjC/lGjRsXll18eU6dOjQkTJsQf//jHmDlzZqxdu7aoddr6TFwAykOeAJAXmQJAHuQJAL1VWZ9QGjlyZES0/eV+W7ZsKYRrsZ/b+qMf/ajwSO8nPvGJA4J1f69//etjxowZERGxbt26+MUvflHUOgB0DnkCQF5kCgB5kCcA9FZlK5QiIk455ZSIiHj66aejqamp1XFPPPFEYXvs2LFFrbFhw4bC9pvf/Obk2PHjx7e4JgBdmzwBIC8yBYA8yBMAeqOyFkqnn356RLz8aO+6detaHffggw8WtidPnlzUGpWVr3xqXyrAIyL27NnT4u8B0LXJEwDyIlMAyIM8AaA3Kmuh9J73vKewvXDhwhbH7Nu3L26//faIiKiuro5p06YVtcYJJ5xQ2H7ooYeSY/cP8f1/D4CuTZ4AkBeZAkAe5AkAvVFZC6WJEyfGlClTIiJiwYIFsXr16oPG3HDDDYVHeK+44oro16/fAfsfeOCBqKioiIqKirjooosO+v23v/3tMXjw4IiI+K//+q947LHHWjyW++67L37wgx9ERMRrX/vaeNOb3lTqnwVAB5MnAORFpgCQB3kCQG9U1kIpIuLGG2+MQYMGRVNTU5x55pkxb968ePjhh2P58uUxa9as+PSnPx0REbW1tTF79uyi56+uro7PfvazERGxdevWeOtb3xpz5syJ5cuXx//8z//Ej3/847j88svj7LPPjn379kVExL/9279Fnz5l/9MByJE8ASAvMgWAPMgTAHqdrAPcc8892WGHHZZFRIs/tbW12VNPPdXi7y5fvrwwbubMmS2O2bdvX3bllVdmFRUVra4REVm/fv2y66+/vix/Y319fWGd+vr6sqwB0FO19x4qTwBIKeYeKlMAaI08OZA8AShdT7uHdshbFqZPnx6//OUv46qrrora2toYPHhwVFdXx4QJE2L+/Pmxfv36qKmpKXn+ioqK+MpXvhKPPPJIfOQjH4k3vOENMXTo0Ojbt28MGzYsxo8fH5/85CfjV7/6VfzTP/1Tjn8ZAB1JngCQF5kCQB7kCQC9SUWWZVlnH0RPsHHjxhg9enRERNTX18eoUaM6+YgAug/30Fc4FwClcw89kPMBUBr3zwM5HwCl62n3UB+qCgAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACR1WKH03HPPxezZs2PMmDFRVVUVI0aMiLq6urj++utj+/btua71k5/8JC666KKoqamJqqqqGDZsWNTW1sb73ve++K//+q/Ytm1brusB0HHkCQB5kSkA5EGeANBbVGRZlpV7kSVLlsSMGTOioaGhxf21tbWxdOnSqKmpOaR1tmzZEhdffHHcfffdyXHr16+PN73pTYe01qtt3LgxRo8eHRER9fX1MWrUqFznB+jJ2nsPlScApBRzD5UpALRGnhxIngCUrqfdQyvLvcD69evjggsuiB07dsSQIUPic5/7XEybNi127NgRixYtim984xvx5JNPxllnnRVr166NoUOHlrTOSy+9FGeccUasW7cuIiLOPffceN/73hcnnnhi9O3bN+rr6+PBBx+M73//+3n+eQB0EHkCQF5kCgB5kCcA9DpZmU2ZMiWLiKyysjJbtWrVQfuvu+66LCKyiMiuueaaktf54Ac/mEVENmDAgOzuu+9uddy+ffuyPXv2lLxOa+rr6wt/R319fe7zA/Rk7bmHyhMA2tLee6hMASBFnhxIngCUrqfdQ8v6HUpr1qyJhx56KCIiLrnkkpg0adJBY2bPnh1jx46NiIgbb7wx9uzZU/Q6K1asiG9/+9sREfGlL30pzj777FbHVlRURGVl2R/MAiBH8gSAvMgUAPIgTwDojcpaKC1evLiwffHFF7d8AH36xIUXXhgRES+++GIsX7686HX+z//5PxERMWzYsPj4xz9e/IEC0KXJEwDyIlMAyIM8AaA3KmuhtGLFioiIqKqqivHjx7c6burUqYXtlStXFrXG7t27C19IeMYZZ8TAgQMjImLv3r1RX18fzz77bOzcubPYQwegC5EnAORFpgCQB3kCQG9U1kJpw4YNERFRU1OTfOR2zJgxB/1Oe/3iF78ohOepp54aDQ0NceWVV8bhhx8exx57bJxwwgkxbNiwOOOMM+KBBx4o/o8AoNPJEwDyIlMAyIM8AaA3KtsHq+7cuTM2b94cERGjRo1Kjh0+fHhUVVVFY2Nj1NfXF7XO448/Xtjet29fTJgwIZ566qkDxuzevTt+8pOfxLJly2LevHnxmc98pqg1IiI2btyY3L9p06ai5wSgbfIEgLzIFADyIE8A6K3KViht3bq1sD1kyJA2xzeH67Zt24pa569//Wthe/78+bFz58545zvfGV/4whfijW98YzQ0NMT3v//9+OxnPxsvvfRSfPazn40xY8bEOeecU9Q6o0ePLmo8APmQJwDkRaYAkAd5AkBvVbaPvNv/M1z79+/f5vgBAwZERMSOHTuKWqexsfGANc8444z44Q9/GHV1dTFgwIA44ogj4iMf+Uj88Ic/jD59Xv5zP/e5z0WWZUWtA0DnkCcA5EWmAJAHeQJAb1W2J5Savygw4uXHb9uya9euiIgYNGhQyetEvPyOjb59+x407vTTT4/zzjsvvve978WGDRviscceize+8Y3tXqetx5I3bdoUEydObPd8ALSPPAEgLzIFgDzIEwB6q7IVSkOHDi1st+eR3uZ3XbTnUeHW1jniiCNi3LhxrY79u7/7u/je974XERGPPPJIUeHa1mfiAlAe8gSAvMgUAPIgTwDorcr2kXcDBw6MkSNHRkTbX+63ZcuWQrgW+7mt+49vKwD3H/vCCy8UtQ4AnUOeAJAXmQJAHuQJAL1V2QqliIhTTjklIiKefvrpaGpqanXcE088UdgeO3ZsUWu8/vWvL2zv3bs3OXb//ZWVZXs4C4CcyRMA8iJTAMiDPAGgNyproXT66adHxMuP9q5bt67VcQ8++GBhe/LkyUWtcdxxx8Wxxx4bERHPPvts8osHf/vb3xa2X/va1xa1DgCdR54AkBeZAkAe5AkAvVFZC6X3vOc9he2FCxe2OGbfvn1x++23R0REdXV1TJs2reh13vve90ZERENDQyxbtqzVcXfddVdhuzn4Aej65AkAeZEpAORBngDQG5W1UJo4cWJMmTIlIiIWLFgQq1evPmjMDTfcEBs2bIiIiCuuuCL69et3wP4HHnggKioqoqKiIi666KIW17nyyitj4MCBERHxyU9+MhoaGg4a853vfCceeOCBiIg466yziv7cWgA6jzwBIC8yBYA8yBMAeqOyFkoRETfeeGMMGjQompqa4swzz4x58+bFww8/HMuXL49Zs2bFpz/96YiIqK2tjdmzZ5e0xrHHHhtf+MIXIiLisccei4kTJ8bChQtj3bp1sXz58vjEJz5RCObDDjssvvKVr+TytwHQceQJAHmRKQDkQZ4A0NuU/Vv6xo0bF3feeWfMmDEjGhoaYs6cOQeNqa2tjaVLl8bQoUNLXudTn/pU/PWvf4358+fHb37zm/jQhz500JgjjzwyFi9eHCeddFLJ6wDQOeQJAHmRKQDkQZ4A0NuU/QmliIjp06fHL3/5y7jqqquitrY2Bg8eHNXV1TFhwoSYP39+rF+/Pmpqag55nXnz5sXKlSvjgx/8YBx//PExYMCAGDZsWNTV1cUXv/jFePLJJ2PSpEk5/EUAdAZ5AkBeZAoAeZAnAPQmFVmWZZ19ED3Bxo0bC59RW19fH6NGjerkIwLoPtxDX+FcAJTOPfRAzgdAadw/D+R8AJSup91DO+QJJQAAAAAAALovhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQ1GGF0nPPPRezZ8+OMWPGRFVVVYwYMSLq6uri+uuvj+3bt5dlze3bt8frXve6qKioiIqKijj++OPLsg4AHUeeAJAXmQJAHuQJAL1FZUcssmTJkpgxY0Y0NDQU/rft27fH2rVrY+3atXHrrbfG0qVLo6amJtd1r7766njmmWdynROAziNPAMiLTAEgD/IEgN6k7E8orV+/Pi644IJoaGiIIUOGxNy5c2PVqlWxbNmyuPTSSyMi4sknn4yzzjortm7dmuu6X/3qV2PgwIExdOjQ3OYFoHPIEwDyIlMAyIM8AaC3KXuhdMUVV8SOHTuisrIy/t//+38xZ86cmDRpUrztbW+LW265Ja677rqIeDlgb7jhhlzW3Lt3b1x66aWxd+/emDNnTowYMSKXeQHoPPIEgLzIFADyIE8A6G3KWiitWbMmHnrooYiIuOSSS2LSpEkHjZk9e3aMHTs2IiJuvPHG2LNnzyGve+ONN8a6devi5JNPjs985jOHPB8AnUueAJAXmQJAHuQJAL1RWQulxYsXF7Yvvvjilg+gT5+48MILIyLixRdfjOXLlx/Sms8991xcffXVERHx9a9/Pfr3739I8wHQ+eQJAHmRKQDkQZ4A0BuVtVBasWJFRERUVVXF+PHjWx03derUwvbKlSsPac3LL788Ghsb44Mf/GD87d/+7SHNBUDXIE8AyItMASAP8gSA3qiynJNv2LAhIiJqamqisrL1pcaMGXPQ75Ri0aJFce+998bw4cNz+2zaZhs3bkzu37RpU67rAfAKeQJAXmQKAHmQJwD0RmUrlHbu3BmbN2+OiIhRo0Ylxw4fPjyqqqqisbEx6uvrS1pvy5YtceWVV0ZExL/927/FEUccUdI8rRk9enSu8wHQPvIEgLzIFADyIE8A6K3K9pF3W7duLWwPGTKkzfFVVVUREbFt27aS1vvUpz4Vf/7zn2PSpElx6aWXljQHAF2PPAEgLzIFgDzIEwB6q7I+odSsPV8SOGDAgIiI2LFjR9Fr/exnP4tvfvObUVlZGV//+tejoqKi6Dna0ta7SDZt2hQTJ07MfV2A3k6eAJAXmQJAHuQJAL1V2QqlgQMHFrZ3797d5vhdu3ZFRMSgQYOKWmfXrl1x2WWXRZZlccUVV8Qb3/jG4g60ndp6hBmA8pAnAORFpgCQB3kCQG9Vto+8Gzp0aGG7PY/0NjY2RkT7HhXe39y5c+M3v/lNjB49Ov71X/+1uIMEoMuTJwDkRaYAkAd5AkBvVdYnlEaOHBl/+ctfYuPGjcmxW7ZsKYRrsV8EOH/+/IiIeMc73hFLlixpcUzz3I2NjbFo0aKIiDjyyCPjbW97W1FrAdDx5AkAeZEpAORBngDQW5WtUIqIOOWUU+Khhx6Kp59+OpqamqKysuXlnnjiicL22LFji1qj+dHihQsXxsKFC5NjN2/eHP/4j/8YERFTp04VrgDdhDwBIC8yBYA8yBMAeqOyfeRdRMTpp58eES+/S2LdunWtjnvwwQcL25MnTy7nIQHQDckTAPIiUwDIgzwBoDcqa6H0nve8p7Dd2jsp9u3bF7fffntERFRXV8e0adOKWiPLsjZ/jjvuuIiIOO644wr/2wMPPFDS3wRAx5MnAORFpgCQB3kCQG9U1kJp4sSJMWXKlIiIWLBgQaxevfqgMTfccENs2LAhIiKuuOKK6Nev3wH7H3jggaioqIiKioq46KKLynm4AHRR8gSAvMgUAPIgTwDojcr6HUoRETfeeGNMnjw5duzYEWeeeWbMmTMnpk2bFjt27IhFixbFLbfcEhERtbW1MXv27HIfDgDdlDwBIC8yBYA8yBMAepuyF0rjxo2LO++8M2bMmBENDQ0xZ86cg8bU1tbG0qVLY+jQoeU+HAC6KXkCQF5kCgB5kCcA9DZl/ci7ZtOnT49f/vKXcdVVV0VtbW0MHjw4qqurY8KECTF//vxYv3591NTUdMShANCNyRMA8iJTAMiDPAGgN6nIsizr7IPoCTZu3BijR4+OiIj6+voYNWpUJx8RQPfhHvoK5wKgdO6hB3I+AErj/nkg5wOgdD3tHtohTygBAAAAAADQfSmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQFKHFUrPPfdczJ49O8aMGRNVVVUxYsSIqKuri+uvvz62b99+SHNv37497rrrrvjoRz8adXV1MXz48OjXr1+MHDkyJk2aFNdee2386U9/yukvAaAzyRMA8iJTAMiDPAGgt6jIsiwr9yJLliyJGTNmRENDQ4v7a2trY+nSpVFTU1P03L/85S9j8uTJsW3btuS4ww47LG655Za44IILil6jPTZu3BijR4+OiIj6+voYNWpUWdYB6Inaew+VJwCkFHMPlSkAtEaeHEieAJSup91Dy/6E0vr16+OCCy6IhoaGGDJkSMydOzdWrVoVy5Yti0svvTQiIp588sk466yzYuvWrUXP39DQUAjWyZMnx7x58+L++++PRx99NH784x/HrFmzok+fPtHQ0BD/+3//77jvvvty/fsA6BjyBIC8yBQA8iBPAOh1sjKbMmVKFhFZZWVltmrVqoP2X3fddVlEZBGRXXPNNUXPv3Llyuz888/Pfv3rX7c6ZvHixVlFRUUWEdmJJ56Y7du3r+h12lJfX1/4O+rr63OfH6Ana889VJ4A0Jb23kNlCgAp8uRA8gSgdD3tHlrWj7xbs2ZNvOUtb4mIiFmzZsXXv/71g8bs27cv3vCGN8SGDRuiuro6nn/++ejXr1/ux/K+970vvv/970dExLp16+LNb35zrvP3tEfXADpSW/dQeQJAe7TnHipTAGiLPDmQPAEoXU+7h5b1I+8WL15c2L744otbPoA+feLCCy+MiIgXX3wxli9fXpZjmTZtWmH7t7/9bVnWAKA85AkAeZEpAORBngDQG5W1UFqxYkVERFRVVcX48eNbHTd16tTC9sqVK8tyLLt27Sps9+3btyxrAFAe8gSAvMgUAPIgTwDojSrLOfmGDRsiIqKmpiYqK1tfasyYMQf9Tt4efPDBwvbYsWOL/v2NGzcm92/atKnoOQFoH3kCQF5kCgB5kCcA9EZlK5R27twZmzdvjoho83MBhw8fHlVVVdHY2Bj19fW5H8svfvGLWLp0aUREnHrqqSWFa/PnHALQseQJAHmRKQDkQZ4A0FuV7SPvtm7dWtgeMmRIm+OrqqoiImLbtm25HseuXbviwx/+cOzduzciIubOnZvr/ACUlzwBIC8yBYA8yBMAequyPqHUrH///m2OHzBgQERE7NixI9fj+PjHPx5r166NiIiZM2fG9OnTS5qnrXeRbNq0KSZOnFjS3AC0Tp4AkBeZAkAe5AkAvVXZCqWBAwcWtnfv3t3m+OYvEBw0aFBuxzBv3ry49dZbIyKirq4ubrrpppLnausRZgDKQ54AkBeZAkAe5AkAvVXZPvJu6NChhe32PNLb2NgYEe17VLg9br755pgzZ05EvPwFiPfee2/hEWMAug95AkBeZAoAeZAnAPRWZSuUBg4cGCNHjoyIiI0bNybHbtmypRCueXwR4B133BGXX355REQcd9xxcf/998fhhx9+yPMC0PHkCQB5kSkA5EGeANBbla1Qiog45ZRTIiLi6aefjqamplbHPfHEE4XtsWPHHtKa99xzT1x44YWxb9++OProo2PZsmUe3QXo5uQJAHmRKQDkQZ4A0BuVtVA6/fTTI+LlR3vXrVvX6rgHH3ywsD158uSS11u2bFmcf/750dTUFCNHjoz7778/TjzxxJLnA6BrkCcA5EWmAJAHeQJAb1TWQuk973lPYXvhwoUtjtm3b1/cfvvtERFRXV0d06ZNK2mtVatWxTnnnBO7du2KYcOGxY9//ON4/etfX9JcAHQt8gSAvMgUAPIgTwDojcpaKE2cODGmTJkSERELFiyI1atXHzTmhhtuiA0bNkRExBVXXBH9+vU7YP8DDzwQFRUVUVFRERdddFGL6/zP//xPnHXWWdHY2BhVVVWxdOnSGD9+fL5/DACdRp4AkBeZAkAe5AkAvVFluRe48cYbY/LkybFjx44488wzY86cOTFt2rTYsWNHLFq0KG655ZaIiKitrY3Zs2cXPf9vf/vb+Lu/+7t48cUXIyLiS1/6UgwbNix+9atftfo7Rx55ZBx55JEl/T0AdA55AkBeZAoAeZAnAPQ2ZS+Uxo0bF3feeWfMmDEjGhoaYs6cOQeNqa2tjaVLl8bQoUOLnv+hhx6K559/vvDPV111VZu/c80118S1115b9FoAdB55AkBeZAoAeZAnAPQ2Zf3Iu2bTp0+PX/7yl3HVVVdFbW1tDB48OKqrq2PChAkxf/78WL9+fdTU1HTEoQDQjckTAPIiUwDIgzwBoDepyLIs6+yD6Ak2btwYo0ePjoiI+vr6GDVqVCcfEUD34R76CucCoHTuoQdyPgBK4/55IOcDoHQ97R7aIU8oAQAAAAAA0H0plAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAEBShxVKzz33XMyePTvGjBkTVVVVMWLEiKirq4vrr78+tm/fnts69913X5x77rkxatSoGDBgQIwaNSrOPffcuO+++3JbA4DOI08AyItMASAP8gSA3qIiy7Ks3IssWbIkZsyYEQ0NDS3ur62tjaVLl0ZNTU3Ja+zbty8uu+yyWLBgQatjPvzhD8fNN98cffrk36Nt3LgxRo8eHRER9fX1MWrUqNzXAOip2nsPlScApBRzD5UpALRGnhxIngCUrqfdQ8v+hNL69evjggsuiIaGhhgyZEjMnTs3Vq1aFcuWLYtLL700IiKefPLJOOuss2Lr1q0lr/PP//zPhWAdN25c3HHHHbFmzZq44447Yty4cRERceutt8a//Mu/HPofBUCHkycA5EWmAJAHeQJAr5OV2ZQpU7KIyCorK7NVq1YdtP+6667LIiKLiOyaa64paY3f/OY3WWVlZRYR2YQJE7Lt27cfsL+xsTGbMGFC4TieeuqpktZJqa+vL/wd9fX1uc8P0JO15x4qTwBoS3vvoTIFgBR5ciB5AlC6nnYPLesTSmvWrImHHnooIiIuueSSmDRp0kFjZs+eHWPHjo2IiBtvvDH27NlT9Dpf/epXo6mpKSIivva1r8WgQYMO2D948OD42te+FhERTU1N8ZWvfKXoNQDoPPIEgLzIFADyIE8A6I3KWigtXry4sH3xxRe3fAB9+sSFF14YEREvvvhiLF++vKg1siyLu+++OyIixowZE6eddlqL40477bQ4+eSTIyLi7rvvjqz8Xx0FQE7kCQB5kSkA5EGeANAblbVQWrFiRUREVFVVxfjx41sdN3Xq1ML2ypUri1rjmWeeiT/+8Y8HzZNa5w9/+EM8++yzRa0DQOeRJwDkRaYAkAd5AkBvVNZCacOGDRERUVNTE5WVla2OGzNmzEG/016PP/54i/PkvQ4AnUeeAJAXmQJAHuQJAL1R64l3iHbu3BmbN2+OiIhRo0Ylxw4fPjyqqqqisbEx6uvri1pn48aNhe221hk9enRh+1DWacn+823atKmouQF6u/3vm82fD95MngDQXqk8iZApALSPPDmQPAEoXVuZ0t2UrVDaunVrYXvIkCFtjm8O123btpVtnaqqqsJ2sevsH8xtmThxYlFzA/CKF154IY4//vjCP8sTAErx6jyJkCkAFE+eHEieAJSupUzpbsr2kXc7d+4sbPfv37/N8QMGDIiIiB07dpRtneY1SlkHgI7x5z//+YB/licAlOLVeRIhUwAonjwBIC8tZUp3U7YnlAYOHFjY3r17d5vjd+3aFRERgwYNKts6zWuUsk5bjws/88wz8Td/8zcREbFq1aqi3t3BwTZt2lR418uaNWvi6KOP7uQj6t6cz/w5p/mqr6+Pt771rRFx8GeDyxN5cii8VvPnnObL+cxXKk8iZIpMOTRer/lyPvPlfOZLnhxInuTL6zVfzmf+nNN8tZUp3U3ZCqWhQ4cWttvzqG1jY2NEtO9R4VLXaV6jlHXa+qza/Y0ePbqo8aQdffTRzmeOnM/8Oaf52v//aIqQJ66t/Hit5s85zZfzma9X50mETHF95cfrNV/OZ76cz3zJkwPJk3x5vebL+cyfc5qvljKluynbR94NHDgwRo4cGRFtf7nfli1bCsFX7Lsc9r+gi/kSQe+mAOge5AkAeZEpAORBngDQW5WtUIqIOOWUUyIi4umnn46mpqZWxz3xxBOF7bFjx5a0xqvnyXsdADqPPAEgLzIFgDzIEwB6o7IWSqeffnpEvPzY7bp161od9+CDDxa2J0+eXNQaJ5xwQhxzzDEHzdOSn/3sZxER8drXvjaOP/74otYBoPPIEwDyIlMAyIM8AaA3Kmuh9J73vKewvXDhwhbH7Nu3L26//faIiKiuro5p06YVtUZFRUWcc845EfHyuzEefvjhFsc9/PDDhXdrnHPOOVFRUVHUOgB0HnkCQF5kCgB5kCcA9EZlLZQmTpwYU6ZMiYiIBQsWxOrVqw8ac8MNN8SGDRsiIuKKK66Ifv36HbD/gQceiIqKiqioqIiLLrqoxXWuvPLK6Nu3b0REfOITn4gdO3YcsH/Hjh3xiU98IiIiKisr48orrzyUPwuADiZPAMiLTAEgD/IEgN6orIVSRMSNN94YgwYNiqampjjzzDNj3rx58fDDD8fy5ctj1qxZ8elPfzoiImpra2P27NklrVFbWxuf+tSnIiJi7dq1MXny5Ljzzjtj7dq1ceedd8bkyZNj7dq1ERHxqU99Kk466aR8/jgAOow8ASAvMgWAPMgTAHqbynIvMG7cuLjzzjtjxowZ0dDQEHPmzDloTG1tbSxdujSGDh1a8jpz586N559/Pr75zW/G+vXr4/3vf/9BYy655JL40pe+VPIaAHQeeQJAXmQKAHmQJwD0NhVZlmUdsdBzzz0XN954YyxdujQ2btwY/fv3j5qamviHf/iH+PjHPx6DBw9u8fceeOCBwmfMzpw5M2677bbkOvfee2/ccsst8cgjj8TmzZvj8MMPj7q6upg1a1a8613vyvvPAqCDyRMA8iJTAMiDPAGgt+iwQgkAAAAAAIDuqezfoQQAAAAAAED3plACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASOpVhdJzzz0Xs2fPjjFjxkRVVVWMGDEi6urq4vrrr4/t27fnts59990X5557bowaNSoGDBgQo0aNinPPPTfuu+++ds/R1NQUX//612PKlClxxBFHxKBBg+LEE0+MWbNmxa9//evcjvVQlPN8bt++Pe6666746Ec/GnV1dTF8+PDo169fjBw5MiZNmhTXXntt/OlPf2pznr/927+NioqKdv10tnKez9tuu63d5+G2225rc77t27fHddddF3V1dTFixIioqqqKMWPGxOzZs+O55547pGPNS7nO57PPPtvuc9n8c/zxx7c4V3e4Pp9//vn44Q9/GFdffXW8613visMPP7xwTBdddFFZ1rzjjjvizDPPjKOOOioGDhwYxx13XMyYMSNWr17d7jnKfY3Kk3zJk/zJlHzJlEMnT1omT/InU/IlT/IlTw6dPGmdTMmXPMmXPMmfTDl0MqVEWS9xzz33ZIcddlgWES3+1NbWZk899dQhrbF3797skksuaXWNiMg+/OEPZ3v37k3O88ILL2R1dXWtzjFgwIDsG9/4xiEd66Eq5/n8xS9+kQ0ZMiR5HiMiO+yww7JFixYl55o6dWqb8zT/dKZyX58LFy5s93lYuHBhcq6nnnoqO+mkk5L/XpYsWVLyseahnOfzmWeeafe5bP4588wzW5yrO1yfqWOaOXNmrmtt3749e/e7393qen369MmuvfbaNucp9zUqT/IlT/InU/IlU/IhTw4mT/InU/IlT/IlT/IhT1omU/IlT/IlT/InU/IhU0rT+f9fjw7w6KOPZoMGDcoiIhsyZEg2d+7cbNWqVdmyZcuySy+99IAXW0NDQ8nrfPazny3MNW7cuOyOO+7I1qxZk91xxx3ZuHHjCvs+97nPtTpHU1NTdvrppxfGnnfeedl9992X/fznP8/+4z/+IzvyyCMLF9m9995b8rEeinKfz4ceeqgwx+TJk7N58+Zl999/f/boo49mP/7xj7NZs2Zlffr0ySIi69u3b/I8NN+4JkyYkD322GPJn87SEdfn/uH64x//OHketmzZ0uo8DQ0NWW1tbWGuSy+9NFu2bFm2atWqbO7cuYX/KBo8eHC2fv360k7IISr3+dy9e3eb19Jjjz2WfeADHyis9d3vfrfFubrD9bl/KB177LHZmWeeWbZwff/731+Ye9q0adnixYuzNWvWZAsWLMhOPPHEwr6bb7651TnKfY3Kk3zJk/zJlHzJlPzIkwPJk/zJlHzJk3zJk/zIk4PJlHzJk3zJk/zJlPzIlNL0ikJpypQpWURklZWV2apVqw7af9111xX+RVxzzTUlrfGb3/wmq6ysLLxItm/ffsD+xsbGbMKECYXjaK0lXrBgQeFYLr/88oP2P/XUU4UGuqamJtuzZ09Jx3soyn0+V65cmZ1//vnZr3/961bHLF68OKuoqMgiIjvxxBOzffv2tTiu+cY1derUoo+jo3TE9bl/uD7zzDMlH+vnP//5wjzXXXfdQftXrlxZeB101jnviPPZlqampuyYY47JIiIbOnToQfeDZt3h+rz66quzJUuWZH/605+yLDvwnSp5huuyZcsK806fPj1ramo6YP8LL7yQHXvssVlEZNXV1dlf//rXFucp9zUqT/IlT/InU/IlU/IjTw4kT/InU/IlT/IlT/IjTw4mU/IlT/IlT/InU/IjU0rT4wuln//854UTPWvWrBbH7N27Nxs7dmzhX9ru3buLXuejH/1oYZ3Vq1e3OGb16tXJ4MyyrHAcI0aMyBobG1scM2/evMI8//3f/130sR6Kjjqf7fHe9763cCzr1q1rcUxXv3F11PnMI1x3796dDRs2LIuIbOzYsa0+xj5r1qzCWmvWrClprVJ1levzRz/6UeE4Lr744lbHdfXrsyXlCtd3vetdhf8gqq+vb3HMHXfckQzOcl+j8iRfXeX1mmU9I0+yTKbkratcoz01U+SJPMlTV3m9ZlnPyBR5kq+ucn3Kk+J0hzzJMpmSt67yes0yeVKM3pInWdZ1rlGZUpzukint1Sd6uMWLFxe2L7744hbH9OnTJy688MKIiHjxxRdj+fLlRa2RZVncfffdERExZsyYOO2001ocd9ppp8XJJ58cERF33313ZFl2wP4nn3wyNmzYEBER559/fgwePLjFefb/UrAf/OAHRR3roeqI89le06ZNK2z/9re/Lcsa5daVzmdbli9fHi+99FJERMycOTP69Gn59uH6jLj99tsL2zNnzsx9/p5m69atsWzZsoiIeMc73hGjRo1qcdx5550Xhx12WES0fG2V+xqVJ/nqKq/XiJ6RJxFd65y2Raa0n0xpP3nyit6UJxFd5/Ua0TMypSudz7bIk/aTJ+3XXfIkQqbkrau8XiPkSUfrDnkS0XXOqUxpv+6UKe3V4wulFStWREREVVVVjB8/vtVxU6dOLWyvXLmyqDWeeeaZ+OMf/3jQPKl1/vCHP8Szzz7b4rG2Nc9RRx0VtbW1JR3roeqI89leu3btKmz37du3LGuUW1c6n21p7/U5YcKEwn8Y9sbrc+vWrYWAP/744+Nv/uZvcp2/J3rkkUdi9+7dEZG+tvr371/4P14eeeSR2LNnzwH7y32NypN8dYXXa7OekCcRXeuctkWmtI9MKY48eUVvypOIrvF6bdYTMqUrnc+2yJP2kSfF6S55sv8aMiUfXeH12kyedKzukCcRXeOcypTidKdMaa8eXyg1v/uhpqYmKisrWx03ZsyYg36nvR5//PEW5yl2nVLmqa+vj8bGxnYf66HqiPPZXg8++GBhe+zYscmxTzzxRLzlLW+J6urqGDhwYIwaNSrOOeecuP322w96gXakzjifF198cRxzzDHRv3//OPzww+O0006Lf/mXf4k//OEPyd9r7/VZWVkZNTU1uRxrsbrC9fm9730vtm/fHhERH/zgB6OioqLN3+mq12dHKeXe19TUFE899VRJ85R6jcqTfHWF12uznpAnETIlb13hGpUpxZEnr+hNeRLRNV6vzXpCpsiTfHWF61OeFKe75Mn+42VKPrrC67WZPClNT86T/deUKd1Hd8qU9urRhdLOnTtj8+bNERGtPk7WbPjw4VFVVRURLwdWMTZu3FjYbmud0aNHF7ZfvU4p82RZdsDvlVNHnc/2+MUvfhFLly6NiIhTTz21zXD985//HGvWrImXXnopdu3aFX/4wx/innvuiZkzZ8ab3vSmTgmBzjqfDzzwQGzatCn27NkTf/nLX+LnP/95zJ07N2pqauLmm29u9fear7Oqqqqorq5OrtF8fb7wwgsHvKumnLrK9bn/Y7/Njxi3pStenx0p73toOa5ReZKvrvJ6jegZeRIhU/LWVa5RmVIcefKK3pInEV3n9RrRMzJFnuSrq1yf8qQ43SFPImRK3rrK6zVCnhyKnponEV3nGpUpxekumVKM1qvMHmDr1q2F7SFDhrQ5vqqqKhobG2Pbtm1lW6f5xRwRB62T1zzl0lHnsy27du2KD3/4w7F3796IiJg7d26rY/v06RNvf/vb493vfnf8r//1v2LkyJGxdevWePTRR+Pmm2+ODRs2xOOPPx7Tpk2LNWvWxLHHHpvrsaZ09Pl83eteF+edd15MmjSpcGP53e9+F9///vfje9/7XuzcuTM+8pGPREVFRVx22WWtHm97j7XZtm3bYsCAASUdczG6wvX5+9//vvAuore+9a2FdwS0pitfnx0p73toOa5ReZKvrvB6jeg5eRIhU/LWFa5RmVI8eVLaOt05TyK6xus1oudkijzJV1e4PuVJ8bpDnhR7nM1ryJTWdYXXa4Q8kSet6wrXqEwpXnfJlGL06EJp586dhe3+/fu3Ob755O7YsaNs6+z/L/DV6+Q1T7l01Plsy8c//vFYu3ZtRLz8JWTTp09vdexdd93VYms7ZcqUuPzyy+PSSy+Nb33rW/HnP/85rrzyyrjrrrtyPdaUjjyf5557bsycOfOgx1Dr6uriggsuiB/+8Idx3nnnxZ49e+Kqq66Ks88+O4466qgWj7eYYy31eEvRFa7P73znO4UvHm3PuzS68vXZkfK+h5bjGpUn+eoKr9eInpMnETIlb13hGpUpxZMnpa3TnfMkomu8XiN6TqbIk3x1hetTnhSvO+RJsce5/xoypWVd4fUaIU/kSeu6wjUqU4rXXTKlGD36I+8GDhxY2G7+8quU5kfABg0aVLZ19n/M7NXr5DVPuXTU+UyZN29e3HrrrRHxcjDcdNNNyfGpRwD79esXt956a5x88skREfGDH/ygzc9UzVNHns9hw4YlP9P07//+7+Pqq6+OiIjt27fHggULDhrTfLzFHGtE77o+v/3tb0fEyzfuCy64oM3xXfn67Eh530PLcY3Kk3x1hddrT8qTCJmSt65wjcqU4smT0tbpznkS0TVerz0pU+RJvrrC9SlPitcd8qTY49x/DZnSsq7wepUn8iSlK1yjMqV43SVTitGjC6WhQ4cWttvzeF/zF/2159GxUtfZ/8sEX71OXvOUS0edz9bcfPPNMWfOnIh4+cvH7r333gMe4StFZWVlXHLJJYV/3v9LD8uts8/nq1122WWFAG7pPDQfbzHHGtF7rs81a9bEE088ERERZ599dpufZ9oenXl9dqS876HluEblSb46+/Xa0/IkovPP6avJlEMjU0ojT0pbpzvnSUTnv157WqZ09vl8NXlyaORJabpDnhR7nPuvIVNa1tmvV3kiT9rS2edUppSmu2RKMXp0oTRw4MAYOXJkRESbX+K3ZcuWwsne/wuw2mP/L9Rqa539v1Dr1euUMk9FRUWbX+iVl446ny2544474vLLL4+IiOOOOy7uv//+OPzwww953oiIU045pbDd0e/W6Kzz2ZIjjzyycDwtnYfm66yxsTFefPHF5FzN1+cRRxzRYZ8l29nns5QvJWyPzro+O1Le99ByXKPyJF/yJH+dfQ98NZlyaGRKaeTJK3pLnkTIlLx19v3v1eTJoZEnpekOeRIhU/ImT/LV2fe/V+vueRLR+edUppSmu2RKMXp0oRTxykX59NNPR1NTU6vjmhvWiIixY8eWtMar5yl2nVLmGT169CG/Y6EYHXE+X+2ee+6JCy+8MPbt2xdHH310LFu2LNf/oEg9FltunXE+U1Lnor3XZ1NTU/z2t7+NiPIea0s663zu2bMnFi1aFBEv/0fKO9/5zkOes1lnXp8dpZR7X2VlZZx00kklzVPqNSpP8iVP8idT8iVTuh95cvAar56n2HW6Q55EyJS8yZN8yZPup7vkyf5ryJR8yJN8yZP8yZTupztlSnv1+ELp9NNPj4iX27t169a1Om7/R+omT55c1BonnHBCHHPMMQfN05Kf/exnERHx2te+No4//vgWj7Wtef70pz/Fk08+WdKxHqqOOJ/7W7ZsWZx//vnR1NQUI0eOjPvvvz9OPPHEkudryeOPP17Ybv732FE6+nymvPDCC7F58+aIaPk8tPf6XLt2beFdED39+my2dOnS+Mtf/hIRER/4wAeisrLykOds1pnXZ0epq6srfKlg6travXt3PPzww4Xf6dev3wH7y32NypN8yZP8yZR8yZTuR568ojflSYRMyZs8yZc86X66S57sv4ZMyYc8yZc8yZ9M6X66U6a0W9bD/fznP88iIouIbNasWS2O2bt3bzZ27NgsIrLq6ups9+7dRa/z0Y9+tLDO6tWrWxyzevXqwpjLL7+8xTHNxzFixIissbGxxTHz5s0rzPPf//3fRR/roeio85llWbZy5cqsqqoqi4hs2LBh2dq1aw/l0Fu0Z8+ewrFGRPb73/8+9zVSOvJ8tuVLX/pS4Vi++MUvHrR/165d2bBhw7KIyMaOHZvt27evxXlmzZpVmGfNmjVlOdbWdNb5PPfccwvrrl+//pDna9bZ12dLnnnmmcLxzJw5M7d53/Wud2URkVVWVmb19fUtjrnjjjsKa1933XUH7S/3NSpP8iVP8idT8iVTykueyJM8yZR8yZN8yZPy6s15kmUyJW/yJF/yJH8ypbx6e6a0V48vlLIsy6ZMmVL4l7Zq1aqD9l933XWFE33NNdcctH/58uVtXky/+c1vsr59+2YRkU2YMCHbvn37Afu3b9+eTZgwoXAcTz75ZIvzLFiwoLDWxz72sYP2P/3009lhhx2WRURWU1OT7dmzp+0TkLOOOJ/r16/Pqqurs4jIqqqqshUrVhR9nD/96U+zLVu2tLp/9+7d2cyZMwvHMn369KLXyEO5z+czzzyTPfroo8ljWLJkSda/f/8sIrJBgwZlGzdubHHc5z//+eTNbdWqVVllZWUWEdnUqVOTa5ZLR1yf+/vLX/5SOHennnpqu4+zu1yfr1ZKuC5cuDB5zrMsy5YtW1YYc/bZZ2dNTU0H7H/hhReyY489tvAfRH/9619bnKfc16g8yZc8yZ9MyZdMKR95Ik/yJlPyJU/yJU/Kp7fnSZbJlLzJk3zJk/zJlPKRKe3TKwqlRx99NBs0aFAWEdmQIUOyL3/5y9nq1auzn/70p9lll11W+BdRW1ubNTQ0HPT77X2hffazny2MGzduXLZo0aLskUceyRYtWpSNGzeusO9zn/tcq3M0NTVlkydPLox973vfm/3oRz/Kfv7zn2df+9rXsiOPPDKLiKxPnz7Zvffem8fpKVq5z+fTTz9d+DsjIvvKV76SPfbYY8mfP//5zwfNM3PmzGzIkCHZBz7wgeyWW27JHnzwwWz9+vXZQw89lH31q1/NTjnllMIaRx55ZPa73/2uHKerTeU+n837J02alH35y1/Oli5dmj3yyCPZI488kt15553ZP/zDP2QVFRWFOW666aZWj7WhoSGrra0tjL3sssuyn/70p9nq1auzL3/5y9mQIUMKAZ3nOxaK0VGv92Y33XRTYfy///u/t/s4u8v1+dBDD2ULFy4s/Fx//fWF45o8efIB+xYuXNjiHO0J1yzLsve///2FcdOmTcvuvvvu7JFHHsm++c1vZieeeGJh380339zqHOW+RuVJvuRJ/mRKvmRKfuTJgeRJ/mRKvuRJvuRJfuTJwWRKvuRJvuRJ/mRKfmRKaXpFoZRlWXbPPfcU3uXQ0k9tbW321FNPtfi77X2h7d27N/vQhz7U6hoRkV1yySXZ3r17k8f6wgsvZHV1da3OMWDAgOwb3/jGoZyOQ1bO87n/C7G9Py29YPdvuVM/p556avbrX/865zNUnHKez/33p34GDx6cvGk1e+qpp7KTTjqp1XkOO+ywbMmSJYd6Sg5JR7zem73lLW/JIiLr27dvtmnTpnYfY3e5Ptt7nM0/LWlvuG7fvj1797vf3ercffr0Sf5+s3Jfo/IkX/IkfzIlXzIlH/LkYPIkfzIlX/IkX/IkH/KkZTIlX/IkX/IkfzIlHzKlNL2mUMqyLHv22Wezq666Kqutrc0GDx6cVVdXZxMmTMjmz5/f6me3ZlnxL7SlS5dm55xzTnbMMcdk/fv3z4455pjsnHPOKerdFXv27Mn+8z//Mzv99NOzkSNHZgMHDsxe97rXZZdeemn2q1/9qt3zlFO5zmde4fr4449nX/nKV7Lzzz8/e8Mb3pC95jWvyfr165cNGTIkO/HEE7MLLrgg+7//9/8e9JhhZynX+WxoaMi+853vZB/72Meyt7zlLdmxxx6bDR48OOvfv3/2mte8Jnvb296WzZ07t8V3vLRm27Zt2fz587MJEyZk1dXV2eDBg7OTTz45u+qqq7Jnn322lD8/dx3xen/yyScLY9/5zncWdXzd5frsyHBt9t3vfjc744wzsiOPPDLr379/Nnr06OwDH/hAi49yt6bc16g8yZc8yZ9MyZdMOXTypGXyJH8yJV/yJF/y5NDJk9bJlHzJk3zJk/zJlEMnU0pTkWVZFgAAAAAAANCKPp19AAAAAAAAAHRtCiUAAAAAAACSFEoAAAAAAAAkKZQAAAAAAABIUigBAAAAAACQpFACAAAAAAAgSaEEAAAAAABAkkIJAAAAAACAJIUSAAAAAAAASQolAAAAAAAAkhRKAAAAAAAAJCmUAAAAAAAASFIoAQAAAAAAkKRQAgAAAAAAIEmhBAAAAAAAQJJCCQAAAAAAgCSFEgAAAAAAAEkKJQAAAAAAAJIUSgAAAAAAACQplAAAAAAAAEhSKAEAAAAAAJCkUAIAAAAAACBJoQQAAAAAAECSQgkAAAAAAIAkhRIAAAAAAABJ/x9PUurkb8HOgQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "image/png": {
              "width": 842,
              "height": 357
            }
          }
        }
      ],
      "source": [
        "# change this to the trainloader or testloader\n",
        "data_iter = iter(testloader)\n",
        "\n",
        "images, labels = next(data_iter)\n",
        "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
        "for ii in range(4):\n",
        "    ax = axes[ii]\n",
        "    helper.imshow(images[ii], ax=ax, normalize=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBFHa7sJ5VEr"
      },
      "source": [
        "Your transformed images should look something like this.\n",
        "\n",
        "<center>Training examples:</center>\n",
        "<img src='assets/train_examples.png' width=500px>\n",
        "\n",
        "<center>Testing examples:</center>\n",
        "<img src='assets/test_examples.png' width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9OoeVOM5VEr"
      },
      "source": [
        "At this point you should be able to load data for training and testing. Now, you should try building a network that can classify cats vs dogs. This is quite a bit more complicated than before with the MNIST and Fashion-MNIST datasets. To be honest, you probably won't get it to work with a fully-connected network, no matter how deep. These images have three color channels and at a higher resolution (so far you've seen 28x28 images which are tiny).\n",
        "\n",
        "In the next part, I'll show you how to use a pre-trained network to build a model that can actually solve this problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LEwB8-255VEs"
      },
      "outputs": [],
      "source": [
        "# Optional TODO: Attempt to build a network to classify cats vs dogs from this dataset\n",
        "#define network\n",
        "\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "        # Dropout module with 0.2 drop probability\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        # Now with dropout\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "\n",
        "        # output so no dropout here\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "from torch import optim\n",
        "\n",
        "model = Classifier()\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "epochs = 30\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        #flatten the images\n",
        "        images = images.view(images.shape[0], -1)\n",
        "\n",
        "        #training phase\n",
        "        #clear grads\n",
        "        optimizer.zero_grad()\n",
        "        #make prediction\n",
        "        output = model(images)\n",
        "        #calculate loss\n",
        "        loss = criterion(output, labels)\n",
        "        #backpass\n",
        "        loss.backward()\n",
        "        #update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # set model to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            #validation Pass\n",
        "            for images, labels in testloader:\n",
        "                #make prediction\n",
        "                log_ps = model(images)\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "\n",
        "                # Get the class probabilities\n",
        "                ps = torch.exp(log_ps)\n",
        "                #use to topk method\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                #define equals\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                #define accuracy\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        train_losses.append(running_loss/len(trainloader))\n",
        "        test_losses.append(test_loss/len(testloader))\n",
        "\n",
        "\n",
        "        print(\"Epoch: {}/{}..\".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}..\".format(running_loss/len(trainloader)),\n",
        "              \"Test Loss: {:.3f}..\".format(test_loss/len(testloader)),\n",
        "              \"Test Accuracy: {:.3f}..\".format(accuracy/len(testloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "HCd3I4tV2Bx6",
        "outputId": "382775f5-a95e-4221-f067-08dd858766e7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0e93bbd4be6e>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m#calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-4368749c283f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Now with dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x150528 and 784x256)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kpw1hGX2XRu",
        "outputId": "e3b7fcdb-9df7-4365-83c0-b2c4af6efb43"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 150528])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cKR1ctagzZIA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}